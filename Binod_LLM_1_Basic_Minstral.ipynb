{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First example:\n",
    "Simple LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "mistral_api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "#mistral_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(\n",
    "      mistral_api_key = mistral_api_key,\n",
    "      model='mistral-large-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Who is Prime Minister of India?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of my last update, the Prime Minister of India is Narendra Modi. He has been serving in this position since 26 May 2014. However, for the most current information, it's always best to check the latest sources, as political positions can change over time.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(message)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As of my last update, the Prime Minister of India is Narendra Modi. He has been serving in this position since 26 May 2014. However, for the most current information, it's always best to check the latest sources, as political positions can change over time.\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 74, 'completion_tokens': 64}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-85f75ede-3f9f-4e46-9b9d-75b360f338e9-0', usage_metadata={'input_tokens': 10, 'output_tokens': 64, 'total_tokens': 74})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my current knowledge up to 2023, the Prime Minister of India is Narendra Modi. He has been serving in this position since 2014. For the most up-to-date information, I recommend checking the latest sources, as political leadership can change."
     ]
    }
   ],
   "source": [
    "# Other way to print in stream way\n",
    "for chunk in llm.stream(message):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a daily exercise plan for IT professionals can help maintain both physical and mental well-being. Given the often sedentary nature of the job, it’s essential to incorporate a balanced routine that includes different types of exercises. Here is a basic daily exercise plan for an IT professional:\n",
      "\n",
      "### Morning Routine\n",
      "**1. Wake up early**\n",
      "- Ideally between 6:00 AM and 7:00 AM to start your day with more energy and focus.\n",
      "\n",
      "**2. Hydrate**\n",
      "- Drink a glass of water immediately upon waking to rehydrate after a night's sleep.\n",
      "\n",
      "**3. Stretch**\n",
      "- Spend 5-10 minutes doing a gentle full-body stretch to increase flexibility and reduce muscle soreness.\n",
      "\n",
      "**4. Quick Cardio**\n",
      "- Do a 5-minute session of light cardio exercises such as jumping jacks, brisk walking, or jogging.\n",
      "\n",
      "### Daily Workout (Evening or Lunchtime)\n",
      "**1. Strength Training (3 days a week)**\n",
      "- Bodyweight exercises: squats, lunges, push-ups, planks, or variations of these to work different muscle groups.\n",
      "- Dumbbells or resistance bands: If you have access to weights, include exercises like bicep curls, tricep dips, and shoulder presses.\n",
      "\n",
      "**2. Cardio (2 days a week)**\n",
      "- High-intensity interval training (HIIT) for 15-20 minutes.\n",
      "- Alternatives: cycling, running, swimming, or using a treadmill for a moderate to intense pace.\n",
      "\n",
      "**3. Flexibility and Balance (1 day a week)**\n",
      "- Yoga or Pilates: Focus on improving flexibility, posture, and core strength.\n",
      "\n",
      "**4. Active Breaks Throughout the Day**\n",
      "- Desk exercises: Every 1-2 hours, take a quick 5-10 minute break to do some stretches, walk around, or do some light exercises like wall push-ups or chair dips.\n",
      "- Walking meetings: Instead of sitting in a conference room or on a Zoom call, try having a meeting while walking (if feasible).\n",
      "\n",
      "**5. Evening Walk/Run**\n",
      "- A brisk 30-minute walk or a short 10-20 minute run to unwind from the day's work and improve cardiovascular health.\n",
      "\n",
      "### Evening Routine\n",
      "**1. Relax and Unwind**\n",
      "- Yoga or deep breathing exercises to lower stress and anxiety.\n",
      "\n",
      "**2. Light Evening Meal**\n",
      "- Opt for a light, nutrient-rich meal. Avoid heavy meals close to bedtime for better sleep quality.\n",
      "\n",
      "**3. Prepare for the Next Day**\n",
      "- Set up your workout gear and meal plan to minimize morning decisions and ensure adherence to the routine.\n",
      "\n",
      "### Weekends\n",
      "- Enjoy outdoor activities: hiking, playing sports, or biking.\n",
      "- Relaxation exercises: Mindfulness meditation or Tai Chi for mental relaxation.\n",
      "\n",
      "### Additional Tips\n",
      "1. **Healthy Eating**: Pay attention to your diet. Eat balanced meals with an emphasis on lean proteins, whole grains, fruits, and vegetables.\n",
      "2. **Posture**: Maintain a good posture while working at the computer. Set up your workspace ergonomically.\n",
      "3. **Adequate Sleep**: Ensure you’re getting 7-9 hours of sleep per night for optimal physical and mental performance.\n",
      "4. **Stay Motivated**: Join a fitness club or an exercise group, or use workout apps to stay motivated.\n",
      "5. **Listen to Your Body**: Take rest days if needed, and adjust exercises or intensity levels as necessary to accommodate your body’s needs.\n",
      "\n",
      "By following this plan consistently, you'll build a healthy habit that boosts your physical and mental health, helping you excel in your professional life as well."
     ]
    }
   ],
   "source": [
    "message = \"Basic excercise for IT professional every day plan?\"\n",
    "for chunk in llm.stream(message):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other way to call Mistral API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='mistral-large-latest'\n",
    "llm_client = Mistral(api_key=mistral_api_key)\n",
    "\n",
    "llm_response = llm_client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[{\"role\":\"user\",\"content\":\"How is Steve Jobs?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm an assistant that operates solely on the data it has been trained on up until 2021, and I don't have real-time or up-to-date information. Steve Jobs, the co-founder and former CEO of Apple, passed away on October 5, 2011. He is widely recognized for his significant contributions to the technology industry, including the development of the Macintosh computer, the iPod, the iPhone, and the iPad. His legacy continues to influence Apple and the broader tech world.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning about Large Language Models (LLMs) like me involves a combination of understanding the underlying theory, practical implementation, and staying updated with the latest research. Here\\'s a roadmap to help you learn about LLMs:\\n\\n### 1. **Foundational Knowledge**\\n   - **Mathematics**: Brush up on linear algebra, calculus, and probability.\\n   - **Machine Learning**: Understand the basics of machine learning, including supervised and unsupervised learning.\\n   - **Natural Language Processing (NLP)**: Familiarize yourself with key concepts in NLP, such as tokenization, POS tagging, and named entity recognition.\\n\\n### 2. **Deep Learning Basics**\\n   - **Neural Networks**: Learn about neural networks, including feedforward neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs).\\n   - **Transformers**: Understand the architecture of transformers, which are the backbone of LLMs.\\n   - **Frameworks**: Get hands-on experience with deep learning frameworks like TensorFlow, PyTorch, and Hugging Face Transformers.\\n\\n### 3. **Specific LLM Concepts**\\n   - **Attention Mechanisms**: Study the attention mechanism, especially self-attention, which is crucial for transformers.\\n   - **Pre-training and Fine-tuning**: Learn about pre-training models on large datasets and fine-tuning them on specific tasks.\\n   - **Model Variants**: Understand different variants of LLMs, such as BERT, RoBERTa, T5, and others.\\n\\n### 4. **Practical Implementation**\\n   - **Data Preparation**: Learn how to prepare and preprocess data for LLMs.\\n   - **Model Training**: Get experience in training LLMs using frameworks like Hugging Face Transformers.\\n   - **Evaluation**: Understand how to evaluate the performance of LLMs using metrics like perplexity, BLEU score, and ROUGE score.\\n\\n### 5. **Advanced Topics**\\n   - **Few-Shot Learning**: Learn about techniques for few-shot learning, where models are trained with limited data.\\n   - **Prompt Engineering**: Understand how to design effective prompts to guide the model\\'s output.\\n   - **Ethical Considerations**: Study the ethical implications of LLMs, including bias, fairness, and privacy.\\n\\n### 6. **Staying Updated**\\n   - **Research Papers**: Regularly read research papers on LLMs from conferences like NeurIPS, ICML, and ACL.\\n   - **Blogs and Tutorials**: Follow blogs and tutorials from experts in the field.\\n   - **Communities**: Join online communities and forums like Kaggle, Reddit, and specialized groups on LinkedIn.\\n\\n### 7. **Hands-On Projects**\\n   - **Courses**: Enroll in online courses and MOOCs that offer hands-on projects.\\n   - **Competitions**: Participate in Kaggle competitions or other data science challenges.\\n   - **Personal Projects**: Work on your own projects to apply what you\\'ve learned.\\n\\n### 8. **Resources**\\n   - **Books**: \"Introduction to Natural Language Processing\" by Jacob Eisenstein, \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\\n   - **Online Courses**: Coursera, Udacity, edX, and fast.ai offer courses on deep learning and NLP.\\n   - **GitHub Repositories**: Explore repositories that contain implementations of LLMs.\\n\\n### 9. **Practice**\\n   - **Coding Practice**: Regularly practice coding in Python, especially with libraries like NumPy, pandas, and scikit-learn.\\n   - **Experimentation**: Experiment with different hyperparameters, architectures, and datasets to see how they affect model performance.\\n\\n### 10. **Documentation and Sharing**\\n   - **Documentation**: Document your learning process, including code, results, and insights.\\n   - **Sharing**: Share your work on platforms like GitHub, Medium, or through academic papers to get feedback and contribute to the community.\\n\\nBy following this roadmap, you\\'ll develop a comprehensive understanding of LLMs and be well-equipped to work on advanced NLP projects.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm_response = llm_client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[{\"role\":\"user\",\"content\":\"how to learn LLM?\"}]\n",
    "    )\n",
    "\n",
    "llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning about Large Language Models (LLMs) like me involves a combination of understanding the underlying theories, technologies, and practical applications. Here\\'s a structured approach to help you learn about LLMs:\\n\\n### 1. **Foundational Knowledge**\\n   - **Natural Language Processing (NLP):** Understand the basics of NLP, including tokenization, parsing, and semantic analysis.\\n   - **Machine Learning:** Familiarize yourself with machine learning concepts, particularly supervised learning and unsupervised learning.\\n   - **Deep Learning:** Study neural networks, especially recurrent neural networks (RNNs) and transformers, which are foundational to LLMs.\\n\\n### 2. **Core Concepts**\\n   - **Transformer Architecture:** Learn about the transformer model, which is the backbone of most modern LLMs. Key topics include self-attention mechanisms and positional encoding.\\n   - **Pre-training and Fine-tuning:** Understand the difference between pre-training (learning general language patterns) and fine-tuning (adapting the model to specific tasks).\\n   - **Language Modeling:** Study how language models generate text by predicting the next word in a sequence.\\n\\n### 3. **Technical Skills**\\n   - **Programming:** Be proficient in Python, as most NLP and LLM frameworks are Python-based.\\n   - **Libraries and Frameworks:** Learn to use libraries like TensorFlow, PyTorch, and Hugging Face\\'s Transformers library.\\n   - **Data Handling:** Understand how to preprocess and manage large datasets, which are essential for training LLMs.\\n\\n### 4. **Practical Experience**\\n   - **Projects:** Work on projects that involve building and deploying LLMs. This could include chatbots, text summarization tools, or any other NLP applications.\\n   - **Research Papers:** Read and understand key research papers in the field, such as \"Attention is All You Need\" by Vaswani et al.\\n   - **Open-Source Contributions:** Contribute to open-source projects related to LLMs to gain hands-on experience.\\n\\n### 5. **Advanced Topics**\\n   - **Fine-tuning Techniques:** Explore advanced fine-tuning techniques like prompt engineering, few-shot learning, and zero-shot learning.\\n   - **Ethical Considerations:** Learn about the ethical implications of LLMs, including bias, fairness, and privacy.\\n   - **Performance Optimization:** Study techniques for optimizing the performance of LLMs, such as model compression and efficient training methods.\\n\\n### 6. **Resources**\\n   - **Books:**\\n     - \"Natural Language Processing with Python\" by Steven Bird, Ewan Klein, and Edward Loper.\\n     - \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\\n   - **Online Courses:**\\n     - Coursera: \"Natural Language Processing\" by Deeplearning.ai.\\n     - Udacity: \"Deep Learning Nanodegree.\"\\n   - **Communities and Forums:**\\n     - Participate in forums like Stack Overflow, Reddit\\'s r/MachineLearning, and specialized groups on LinkedIn.\\n     - Join NLP and LLM communities on platforms like GitHub and Kaggle.\\n\\n### 7. **Stay Updated**\\n   - **Conferences and Workshops:** Attend conferences like NeurIPS, ACL, and EMNLP to stay updated on the latest research.\\n   - **Journals and Blogs:** Follow journals like the Journal of Machine Learning Research and blogs from leading AI companies.\\n   - **Networking:** Connect with professionals and researchers in the field through social media, meetups, and professional organizations.\\n\\nBy following these steps, you can build a strong foundation in LLMs and stay current with the latest developments in the field. Happy learning!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHANGE ROLE and see the response\n",
    "llm_response = llm_client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[{\"role\":\"system\",\"content\":\"how to learn LLM?\"}]\n",
    "    )\n",
    "\n",
    "llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning about Large Language Models (LLMs) like me involves a combination of understanding the underlying theory, practical implementation, and staying updated with the latest research. Here\\'s a roadmap to help you learn about LLMs:\\n\\n### 1. **Foundational Knowledge**\\n   - **Mathematics**: Ensure you have a strong foundation in linear algebra, calculus, probability, and statistics.\\n   - **Machine Learning**: Understand the basics of machine learning, including supervised and unsupervised learning, neural networks, and deep learning.\\n   - **Natural Language Processing (NLP)**: Familiarize yourself with NLP concepts such as tokenization, part-of-speech tagging, named entity recognition, and text classification.\\n\\n### 2. **Deep Learning**\\n   - **Neural Networks**: Learn about different types of neural networks, including feedforward neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs).\\n   - **Transformers**: Study the architecture of transformers, which are the backbone of LLMs. Understand concepts like self-attention, multi-head attention, and positional encoding.\\n\\n### 3. **Specific LLM Concepts**\\n   - **Pre-training and Fine-tuning**: Learn about pre-training techniques like masked language modeling and next sentence prediction. Understand how models are fine-tuned for specific tasks.\\n   - **Transfer Learning**: Study how transfer learning is applied in LLMs to leverage pre-trained models for new tasks.\\n   - **Prompt Engineering**: Learn about prompt engineering, which involves designing input prompts to guide the model\\'s output effectively.\\n\\n### 4. **Practical Implementation**\\n   - **Programming Languages**: Be proficient in Python, as it is widely used in machine learning and deep learning.\\n   - **Frameworks and Libraries**: Get hands-on experience with frameworks like TensorFlow, PyTorch, and libraries like Hugging Face\\'s Transformers.\\n   - **Datasets**: Work with large datasets and understand data preprocessing techniques.\\n\\n### 5. **Hands-On Projects**\\n   - **Build Your Own Models**: Start with simple projects like text classification or sentiment analysis, and gradually move to more complex tasks like question answering and machine translation.\\n   - **Experiment with Pre-trained Models**: Use pre-trained models from Hugging Face and fine-tune them for your specific tasks.\\n\\n### 6. **Stay Updated**\\n   - **Research Papers**: Read the latest research papers on LLMs from conferences like NeurIPS, ICML, and ACL.\\n   - **Online Courses and Tutorials**: Enroll in online courses and tutorials from platforms like Coursera, edX, and Udacity.\\n   - **Communities and Forums**: Join communities and forums like Stack Overflow, Reddit, and specialized groups on LinkedIn to discuss and learn from others.\\n\\n### 7. **Advanced Topics**\\n   - **Ethical Considerations**: Understand the ethical implications of LLMs, including bias, fairness, and privacy concerns.\\n   - **Scalability and Efficiency**: Learn about techniques to make LLMs more scalable and efficient, such as model compression and quantization.\\n   - **Interpretability**: Study methods to interpret and explain the outputs of LLMs.\\n\\n### 8. **Resources**\\n   - **Books**: \"Deep Learning\" by Ian Goodfellow, \"Natural Language Processing with Python\" by Steven Bird, Ewan Klein, and Edward Loper.\\n   - **Online Courses**: \"Deep Learning Specialization\" by Andrew Ng on Coursera, \"Natural Language Processing with Deep Learning\" by Stanford University.\\n   - **Research Papers**: \"Attention is All You Need\" by Vaswani et al., \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" by Devlin et al.\\n\\nBy following this roadmap, you can build a strong foundation in LLMs and stay updated with the latest developments in the field.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = llm_client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[{\"role\":\"user\",\"content\":\"how to learn LLM?\"}],\n",
    "    #To make response more specific use 0.6 or below, for generic make .9 or 1\n",
    "    temperature = 0.3\n",
    "   \n",
    ")\n",
    "\n",
    "llm_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-env-mistral",
   "language": "python",
   "name": "poetry-env-mistral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
